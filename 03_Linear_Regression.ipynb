{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Lab 3: Linear Regression\n","\n","In this lab, we will walkthrough the basic implementation of several regression methods. First, we will cover simple linear regression, for when we have one predictor (X). Next, we will cover Multiple Linear Regression, for when we have multiple predictors. We will then cover two regularization methods."],"metadata":{"id":"yrkFbZO_KY6o"}},{"cell_type":"markdown","source":["## Part 1: Simple Linear Regression\n","\n","In Part 1, we will perform Simple Linear Regression using Python.\n","We will use the `pandas`, `numpy`, `scipy`, and `scikit-learn` libraries for data manipulation and modeling. We will also visualize the results using `matplotlib`."],"metadata":{"id":"ABbfaIsOLltw"}},{"cell_type":"markdown","source":["### Step 1: Import Libraries\n","\n","First, we need to import the necessary libraries. Run the following code:\n","\n","```python\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LinearRegression, Lasso, Ridge\n","from sklearn.metrics import mean_squared_error, r2_score\n","from scipy import stats\n","```\n","\n","#### <font color='red'>**TRY IT**</font> &#x1f9e0;: Get everything imported!"],"metadata":{"id":"BGy2WnMddwK2"}},{"cell_type":"markdown","source":["### Step 2: Load the Dataset\n","Next, we will load a dataset. For this tutorial, we will use some simulated house pricing data.\n","\n","```python\n","# Manually creating the synthetic dataset\n","data = {\n","    'SquareFootage': [3532, 3407, 2453, 1635, 1563, 2531, 1833, 1077, 2578, 2628,\n","                      3447, 3942, 3448, 3162, 1505, 3399, 2935, 3022, 3697, 2501],\n","    'NumBedrooms': [2, 1, 2, 5, 4, 1, 4, 1, 3, 4,\n","                    1, 2, 4, 4, 4, 1, 2, 2, 2, 1],\n","    'AgeOfHouse': [31, 10, 23, 35, 11, 28, 34, 0, 0, 36,\n","                   5, 38, 40, 17, 15, 4, 41, 42, 31, 1],\n","    'Price': [838560.919253, 804484.724846, 563445.633404, 432226.399244, 408372.745913,\n","              548757.706247, 440905.015175, 248148.490314, 625590.329047, 644081.556976,\n","              817637.919091, 953896.908492, 846710.103200, 799152.331779, 385981.010762,\n","              806350.318599, 659057.167194, 687884.192489, 886352.154312, 563846.859079]\n","}\n","\n","# Create the DataFrame\n","df = pd.DataFrame(data)\n","\n","# Display the DataFrame\n","print(df)\n","```\n","\n","#### <font color='red'>**TRY IT**</font> &#x1f9e0;: Create this dataset!"],"metadata":{"id":"7KqZbqkGL5wI"}},{"cell_type":"markdown","source":["### Step 3: Split the Data\n","Now we will split the data into training and testing sets. Let's select `SquareFootage` as our single predictor. We want to keep 80% of the data aside for training and leave the remaining 20% for testing.\n","\n","```python\n","# split the data into test and train sets\n","X_train, X_test, y_train, y_test = train_test_split(df[['XXX']], df['YYY'], test_size=XXX, random_state=26)\n","```\n","#### <font color='red'>**TRY IT**</font> &#x1f9e0;: Split the data!"],"metadata":{"id":"Hv691pyML_Wv"}},{"cell_type":"markdown","source":["### Step 4: Visualize the Data\n","Let's visualize the data to understand the relationship between the feature and the target variable.\n","\n","```python\n","# visualize our data\n","plt.scatter(XXXX, YYYY, color='blue')\n","plt.title('Scatter Plot of Feature vs Target')\n","plt.xlabel('Feature')\n","plt.ylabel('Target')\n","plt.grid()\n","plt.show()\n","```\n","\n","#### <font color='red'>**TRY IT**</font> &#x1f9e0;:  Visualize our data. Can you make an estimate for the intercept and slope just by looking at it?"],"metadata":{"id":"xNQ6vzTHL822"}},{"cell_type":"markdown","source":["### Step 5: Create and Train the Model\n","Now, we'll create a linear regression model and fit it to our training data. Documentation for LinearRegression can be found [here](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html).\n","\n","```python\n","# specify the model\n","model = LinearRegression()\n","\n","# fit the model\n","model.fit(XXX, XXX)\n","\n","# print the slope and intercept coefficients\n","beta1 = model.XXX[0] # we specify 0 here because coefficients are returned as a list\n","beta0 = model.XXX\n","print(f'Coefficient: {beta1}')\n","print(f'Intercept: {beta0}')\n","```\n","#### <font color='red'>**TRY IT**</font> &#x1f9e0;: The time has come, train your first model!"],"metadata":{"id":"V7ZSEOjJMB3K"}},{"cell_type":"markdown","source":["### Step 6: Visualize the Regression Line\n","After training the model, we can make predictions on the training data to plot the line.\n","\n","```python\n","# Make predictions\n","y_pred = model.XXX(XXX)\n","\n","# Plotting\n","plt.figure(figsize=(10, 6))\n","\n","# Scatter plot of actual data\n","plt.scatter(df['XXX'], df['YYY'], color='blue', label='Actual Data')\n","\n","# Plotting the regression line\n","plt.plot(X_train, y_pred, color='orange', linewidth=2, label='Regression Line')\n","\n","# Add titles and labels\n","plt.title('Linear Regression Model')\n","plt.xlabel('Feature')\n","plt.ylabel('Target')\n","plt.legend()\n","plt.grid()\n","plt.show()\n","```\n","\n","#### <font color='red'>**TRY IT**</font> &#x1f9e0;: Use the code above to plot the data points and the regression line for the training data (we have not moved on to test yet!).\n"],"metadata":{"id":"PtC4FU2_MEFJ"}},{"cell_type":"markdown","source":["### Step 7: Evaluate Accuracy of Coefficients\n","Now, we will evaluate the accuracy of the coefficients using standard errors.\n","\n","```python\n","# extract the columns into an array for easier processing\n","X = df['XXX'].values\n","y = df['YYY'].values\n","\n","# get number of observations\n","n = len(y)\n","\n","# Calculate the means\n","X_mean = np.mean(X)\n","y_mean = np.mean(y)\n","\n","# Calculate residuals\n","residuals = y_train - y_pred\n","\n","# Calculate the residual standard error (RSE)\n","rse = XXX\n","\n","# Calculate the SE for each beta\n","se_beta1 = rse / np.sqrt(np.sum((X - X_mean) ** 2))\n","se_beta0 = rse * np.sqrt((1/n) + (X_mean**2 / np.sum((X - X_mean) ** 2)))\n","\n","# Print the coefficients and their standard errors\n","beta1 = model.coef_[0]\n","beta0 = model.intercept_\n","\n","# Print the results\n","print(f\"Beta0 (Intercept): {beta0}, Standard Error: {se_beta0}\")\n","print(f\"Beta1 (Slope): {beta1}, Standard Error: {se_beta1}\")\n","```\n","\n","#### <font color='red'>**TRY IT**</font> &#x1f9e0;: Evaluate the model you just trained. Are the coefficients reasonable estimates?"],"metadata":{"id":"G9Yj0PlAMJ0X"}},{"cell_type":"markdown","source":["**Interpretation of Beta1 and it's SE**: For each additional square foot, the predicted house price increases by about `Beta1` dollars, on average, holding everything else constant (which here is nothing else). A standard error of about `se_beta0` dollars means that if we repeated this study many times with different samples of houses, the estimated price increase per square foot would usually vary by only about `se_beta0` dollars from the true value.\n","\n","**Interpretation of Beta0 and its SE:** `Beta0` represents the predicted house price when square footage is zero. While this value does not have a meaningful real-world interpretation (since a house can't have zero square feet!), it serves as the baseline that positions the regression line. A standard error of about `se_beta0` dollars means that if we repeated this study many times with different samples of houses, the estimated baseline price would typically vary by about `se_beta0`.\n","\n","\n","\n","Next, we can calculate the **t-statistic** for `Beta1` to help us determine if there truly is a relationship between our predictor and target variable.\n","\n","\n","```python\n","# Calculate t-statistic for Beta1\n","t_stat = XXX / XXX\n","\n","# Calculate the p-value (two-tailed)\n","p_value = 2 * (1 - stats.t.cdf(np.abs(t_stat), n-2))\n","\n","# display results\n","print(f\"t-statistic for Beta1: {t_stat}, p-value: {p_value}\")\n","```\n","\n","#### <font color='red'>**TRY IT**</font> &#x1f9e0;: Is there truly a relationships between our predictor and target?"],"metadata":{"id":"X99Wjcm4XWiO"}},{"cell_type":"markdown","source":["### Step 8: Evaluate the Model\n","\n","**Residual Standard Error (RSE)**: We will calculate the Residual Standard Error to give us an idea of the average distance that the observed values fall from the predicted values.\n","\n","```python\n","# get the test set residuals and calculate RSE\n","residuals = y_train - y_pred\n","rse = np.sqrt(mean_squared_error(y_train, y_pred))\n","print(f'Residual Standard Error (RSE): {rse:.2f}')\n","```\n","\n","**R-squared Value**: We will evaluate the model using the R-squared value to tell us the proportion of variance in the response variable that is explained by the predictor variable.\n","\n","```python\n","# calculate r squared\n","r2 = r2_score(y_train, y_pred)\n","print(f'R-squared: {r2:.2f}')\n","```\n","#### <font color='red'>**TRY IT**</font> &#x1f9e0;: What do RSE and R-squared tell you about this model?"],"metadata":{"id":"IsdoPrxGMGHl"}},{"cell_type":"markdown","source":["## Part 2: Multiple Linear Regression\n","\n","In Part 2, we will perform Multiple Linear Regression using Python. This allows us to use multiple predictors. Let's say we want to include `AgeOfHouse` in our model. The code for splitting data, specifying the model, and fitting the model is entirely the same as with Simple Linear Regression. The only difference is in how we specify our X values:\n","\n","```python\n","# Prepare the data\n","X = df[['SquareFootage', 'AgeOfHouse']].values  # IVs\n","```\n","\n","#### <font color='red'>**TRY IT**</font> &#x1f9e0;: Create the X values as above, then use the code from previously to specify y, split the data, specify the model and fit it, and predict using our `X_train` data and call it `y_train_predict`.\n","\n","\n","\n"],"metadata":{"id":"9jZUhTiORaak"}},{"cell_type":"markdown","source":["Then we can evaluate the model and it's fit:\n","\n","```python\n","# Calculate F-statistic\n","residuals = y_train - y_train_pred # Residuals\n","n = len(y_train)  # Number of observations\n","p = X_train.shape[1]  # Number of predictors\n","rss = np.sum(residuals**2)  # Residual sum of squares\n","tss = np.sum((y_train - np.mean(y_train))**2)  # Total sum of squares\n","f_statistic = (tss - rss) / p / (rss / (n - p - 1)) # get F\n","f_p_value = 1 - stats.f.cdf(f_statistic, p, n - p - 1) # get p\n","print(f\"F-statistic: {f_statistic}, p-value: {f_p_value}\")\n","\n","# Calculate R-squared\n","r_squared = model.score(X_train, y_train)\n","print(f\"R-squared: {r_squared}\")\n","\n","# Calculate RSE\n","rse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n","print(f\"Residual Standard Error (RSE): {rse}\")\n","```\n","\n","#### <font color='red'>**TRY IT**</font> &#x1f9e0;: Assess the model overall. Is there at least one predictor which is related to our target? How good is the fit?"],"metadata":{"id":"H7mfYaIZ04uM"}}]}