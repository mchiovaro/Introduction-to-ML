{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Lab 3: Linear Regression\n",
        "\n",
        "In this lab, we will walkthrough the basic implementation of several regression methods. First, we will cover simple linear regression, for when we have one predictor (X). Next, we will cover Multiple Linear Regression, for when we have multiple predictors. We will then cover two regularization methods."
      ],
      "metadata": {
        "id": "yrkFbZO_KY6o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1: Simple Linear Regression\n",
        "\n",
        "In Part 1, we will perform Simple Linear Regression using Python.\n",
        "We will use the `pandas`, `numpy`, `scipy`, and `scikit-learn` libraries for data manipulation and modeling. We will also visualize the results using `matplotlib`."
      ],
      "metadata": {
        "id": "ABbfaIsOLltw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1: Import Libraries\n",
        "\n",
        "First, we need to import the necessary libraries. Run the following code:\n",
        "\n",
        "```python\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from scipy import stats\n",
        "```\n",
        "\n",
        "#### <font color='red'>**TRY IT**</font> &#x1f9e0;: Get everything imported!"
      ],
      "metadata": {
        "id": "BGy2WnMddwK2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2: Load the Dataset\n",
        "Next, we will load a dataset. For this tutorial, we will use some simulated house pricing data.\n",
        "\n",
        "```python\n",
        "# Manually creating the synthetic dataset\n",
        "data = {\n",
        "    'SquareFootage': [3532, 3407, 2453, 1635, 1563, 2531, 1833, 1077, 2578, 2628,\n",
        "                      3447, 3942, 3448, 3162, 1505, 3399, 2935, 3022, 3697, 2501],\n",
        "    'NumBedrooms': [2, 1, 2, 5, 4, 1, 4, 1, 3, 4,\n",
        "                    1, 2, 4, 4, 4, 1, 2, 2, 2, 1],\n",
        "    'AgeOfHouse': [31, 10, 23, 35, 11, 28, 34, 0, 0, 36,\n",
        "                   5, 38, 40, 17, 15, 4, 41, 42, 31, 1],\n",
        "    'Price': [838560.919253, 804484.724846, 563445.633404, 432226.399244, 408372.745913,\n",
        "              548757.706247, 440905.015175, 248148.490314, 625590.329047, 644081.556976,\n",
        "              817637.919091, 953896.908492, 846710.103200, 799152.331779, 385981.010762,\n",
        "              806350.318599, 659057.167194, 687884.192489, 886352.154312, 563846.859079]\n",
        "}\n",
        "\n",
        "# Create the DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Display the DataFrame\n",
        "print(df)\n",
        "```\n",
        "\n",
        "#### <font color='red'>**TRY IT**</font> &#x1f9e0;: Create this dataset!"
      ],
      "metadata": {
        "id": "7KqZbqkGL5wI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3: Visualize the Data\n",
        "Let's visualize the data to understand the relationship between the feature and the target variable.\n",
        "\n",
        "```python\n",
        "# visualize our data\n",
        "plt.scatter(df['XXX'], df['YYY'], color='blue')\n",
        "plt.title('Scatter Plot of Feature vs Target')\n",
        "plt.xlabel('Feature')\n",
        "plt.ylabel('Target')\n",
        "plt.grid()\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "#### <font color='red'>**TRY IT**</font> &#x1f9e0;:  Visualize our data. Can you make an estimate for the intercept and slope just by looking at it?"
      ],
      "metadata": {
        "id": "xNQ6vzTHL822"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 4: Split the Data\n",
        "Now we will split the data into training and testing sets.\n",
        "\n",
        "```python\n",
        "# split the data into test and train sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(df[['XXX']], df['YYY'], test_size=0.2, random_state=42)\n",
        "```\n",
        "#### <font color='red'>**TRY IT**</font> &#x1f9e0;: Split the data!"
      ],
      "metadata": {
        "id": "Hv691pyML_Wv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 5: Create and Train the Model\n",
        "Now, we'll create a linear regression model and fit it to our training data.\n",
        "\n",
        "```python\n",
        "# specify the model\n",
        "model = LinearRegression()\n",
        "\n",
        "# fit the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# print the coefficients\n",
        "beta1 = model.coef_\n",
        "beta0 = model.intercept_\n",
        "print(f'Coefficient: {beta1[0]}') # we specify 0 here because coefficients are returned as a list\n",
        "print(f'Intercept: {beta0}')\n",
        "```\n",
        "#### <font color='red'>**TRY IT**</font> &#x1f9e0;: The time has come, train your first model!"
      ],
      "metadata": {
        "id": "V7ZSEOjJMB3K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 6: Visualize the Regression Line\n",
        "After training the model, we can make predictions on the training data to plot the line.\n",
        "\n",
        "```python\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_train)\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Scatter plot of actual data\n",
        "plt.scatter(df['XXX'], df['YYY'], color='blue', label='Actual Data')\n",
        "\n",
        "# Plotting the regression line\n",
        "plt.plot(X_train, y_pred, color='orange', linewidth=2, label='Regression Line')\n",
        "\n",
        "# Add titles and labels\n",
        "plt.title('Linear Regression Model')\n",
        "plt.xlabel('Feature')\n",
        "plt.ylabel('Target')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "#### <font color='red'>**TRY IT**</font> &#x1f9e0;: Use the code above to plot the data points and the regression line.\n"
      ],
      "metadata": {
        "id": "PtC4FU2_MEFJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 7: Evaluate Accuracy of Coefficients\n",
        "Now, we will evaluate the accuracy of the coefficients using standard errors.\n",
        "\n",
        "```python\n",
        "# get the regression line\n",
        "y_pred = model.predict(X_train)\n",
        "\n",
        "# extract the columns\n",
        "X = df['XXX'].values\n",
        "y = df['YYY'].values\n",
        "\n",
        "# get number of observations\n",
        "n = len(y)\n",
        "\n",
        "# Calculate the means\n",
        "X_mean = np.mean(X)\n",
        "y_mean = np.mean(y)\n",
        "\n",
        "# Calculate residuals\n",
        "residuals = y_train - y_pred\n",
        "\n",
        "# Calculate the residual standard error (RSE)\n",
        "rse = np.sqrt(np.sum(residuals**2) / (len(y_train) - 2))\n",
        "\n",
        "# Calculate the SE for each beta\n",
        "se_beta1 = rse / np.sqrt(np.sum((X - X_mean) ** 2))\n",
        "se_beta0 = rse * np.sqrt((1/n) + (X_mean**2 / np.sum((X - X_mean) ** 2)))\n",
        "\n",
        "# Print the coefficients and their standard errors\n",
        "beta1 = model.coef_[0]\n",
        "beta0 = model.intercept_\n",
        "\n",
        "# Print the results\n",
        "print(f\"Beta0 (Intercept): {beta0}, Standard Error: {se_beta0}\")\n",
        "print(f\"Beta1 (Slope): {beta1}, Standard Error: {se_beta1}\")\n",
        "```\n",
        "\n",
        "#### <font color='red'>**TRY IT**</font> &#x1f9e0;: Evaluate the model you just trained. Are the coefficients reasonable estimates?"
      ],
      "metadata": {
        "id": "G9Yj0PlAMJ0X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we can calculate the t-statistic for beta1 to help us determine if there truly is a relationship between our predictor and target variable.\n",
        "\n",
        "\n",
        "```python\n",
        "# Calculate t-statistic for Beta1\n",
        "t_stat = beta1 / se_beta1\n",
        "\n",
        "# Calculate the p-value (two-tailed)\n",
        "p_value = 2 * (1 - stats.t.cdf(np.abs(t_stat), n-2))\n",
        "\n",
        "# display results\n",
        "print(f\"t-statistic for Beta1: {t_stat}, p-value: {p_value}\")\n",
        "```\n",
        "\n",
        "#### <font color='red'>**TRY IT**</font> &#x1f9e0;: Is there truly a relationships between our predictor and target?"
      ],
      "metadata": {
        "id": "X99Wjcm4XWiO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 8: Evaluate the Model\n",
        "\n",
        "**Residual Standard Error (RSE)**: We will calculate the Residual Standard Error to give us an idea of the average distance that the observed values fall from the predicted values.\n",
        "\n",
        "```python\n",
        "# get predictions from the test set\n",
        "y_pred = model.predict(X_train)\n",
        "\n",
        "# get the test set residuals and calculate RSE\n",
        "residuals = y_train - y_pred\n",
        "rse = np.sqrt(mean_squared_error(y_train, y_pred))\n",
        "print(f'Residual Standard Error (RSE): {rse:.2f}')\n",
        "```\n",
        "\n",
        "**R-squared Value**: We will evaluate the model using the R-squared value to tell us the proportion of variance in the response variable that is explained by the predictor variable.\n",
        "\n",
        "```python\n",
        "# calculate r squared\n",
        "r2 = r2_score(y_train, y_pred)\n",
        "print(f'R-squared: {r2:.2f}')\n",
        "```\n",
        "#### <font color='red'>**TRY IT**</font> &#x1f9e0;: What do RSE and R-squared tell you about this model?"
      ],
      "metadata": {
        "id": "IsdoPrxGMGHl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2: Multiple Linear Regression\n",
        "\n",
        "In Part 2, we will perform Multiple Linear Regression using Python. This allows us to use multiple predictors. Let's say we want to include `AgeOfHouse` in our model. The code for splitting data, specifying the model, and fitting the model is entirely the same as with Simple Linear Regression. The only difference is in how we specify our X values:\n",
        "\n",
        "```python\n",
        "# Prepare the data\n",
        "X = df[['SquareFootage', 'AgeOfHouse']].values  # IVs\n",
        "```\n",
        "\n",
        "#### <font color='red'>**TRY IT**</font> &#x1f9e0;: Create the X values as above, then use the code from previously to specify y, split the data, specify the model and fit it, and predict using our `X_train` data and call it `y_train_predict`.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9jZUhTiORaak"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then we can evaluate the model and it's fit:\n",
        "\n",
        "```python\n",
        "# Calculate F-statistic\n",
        "residuals = y_train - y_train_predict # Residuals\n",
        "n = len(y_train)  # Number of observations\n",
        "p = X_train.shape[1]  # Number of predictors\n",
        "rss = np.sum(residuals**2)  # Residual sum of squares\n",
        "tss = np.sum((y_train - np.mean(y_train))**2)  # Total sum of squares\n",
        "f_statistic = (tss - rss) / p / (rss / (n - p - 1)) # get F\n",
        "f_p_value = 1 - stats.f.cdf(f_statistic, p, n - p - 1) # get p\n",
        "print(f\"F-statistic: {f_statistic}, p-value: {f_p_value}\")\n",
        "\n",
        "# Calculate R-squared\n",
        "r_squared = model.score(X_train, y_train)\n",
        "print(f\"R-squared: {r_squared}\")\n",
        "\n",
        "# Calculate RSE\n",
        "rse = np.sqrt(mean_squared_error(y_train, y_train_predict))\n",
        "print(f\"Residual Standard Error (RSE): {rse}\")\n",
        "```\n",
        "\n",
        "#### <font color='red'>**TRY IT**</font> &#x1f9e0;: Assess the model overall. Is there at least one predictor which is related to our target? How good is the fit?"
      ],
      "metadata": {
        "id": "H7mfYaIZ04uM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Subset Selection Methods\n",
        "\n",
        "**It's time to fly!**\n",
        "\n",
        "Below, I've laid out how to make a function for forward selection. Read through it with your table-mates.\n",
        "\n",
        "```python\n",
        "```python\n",
        "def forward_selection(X, y):\n",
        "    \"\"\"\n",
        "    Perform forward selection to identify significant\n",
        "    predictors using Adjusted-R squared.\n",
        "    \n",
        "    Parameters:\n",
        "    X : array-like, shape (n_samples, n_features)\n",
        "        The input data.\n",
        "    y : array-like, shape (n_samples,)\n",
        "        The target variable.\n",
        "    \n",
        "    Returns:\n",
        "    list : Indices of the selected significant features.\n",
        "    \"\"\"\n",
        "    initial_features = list(range(X.shape[1]))\n",
        "    best_features = [] # initialize storage of best features\n",
        "    n = len(y)  # Number of samples\n",
        "\n",
        "    # continue while there are still features left to test\n",
        "    while initial_features:\n",
        "        best_feature = None # to store the best feature for this iteration\n",
        "        best_adj_r_squared = float('-inf')  # start with negative infinity\n",
        "\n",
        "        # evaluate each feature to find the best one to add\n",
        "        for feature in initial_features:\n",
        "\n",
        "            # specify and fit the model\n",
        "            model = LinearRegression()\n",
        "            model.fit(X[:, best_features + [feature]], y)\n",
        "            print(f\"Adding {feature} to the model. Testing...\")\n",
        "\n",
        "            # Calculate Adjusted R-squared\n",
        "            r_squared = model.score(X[:, best_features + [feature]], y) # R-squared\n",
        "            p = len(best_features) + 1  # Number of predictors in the model\n",
        "            adj_r_squared = 1 - (1 - r_squared) * (n - 1) / (n - p - 1)\n",
        "\n",
        "            # If the current Adjusted R-squared is better, update the best feature\n",
        "            if adj_r_squared > best_adj_r_squared:  # Use Adjusted R-squared to find the best feature\n",
        "                best_adj_r_squared = adj_r_squared\n",
        "                best_feature = feature\n",
        "        \n",
        "        # if a best feature was found, add it to the list\n",
        "        if best_feature is not None:\n",
        "            best_features.append(best_feature)\n",
        "            print(f\"New best set of features: {best_features}\")\n",
        "            initial_features.remove(best_feature) # remove it from list to test\n",
        "\n",
        "    return best_features\n",
        "\n",
        "# Specify data\n",
        "X = df[['SquareFootage', 'NumBedrooms', 'AgeOfHouse']].values\n",
        "y = df['Price'].values\n",
        "\n",
        "# split the data into test and train sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Perform forward selection\n",
        "significant_features_indices = forward_selection(X_train, y_train)\n",
        "\n",
        "# Display the results\n",
        "print(f\"Significant features: {[df.columns[i] for i in significant_features_indices]}\")\n",
        "```\n",
        "\n",
        "Once you understand each step, take a look at ***Backward Selection*** on *page 87* of our textbook. If you want further details, see ***Backward Stepwise Selection*** on *page 234-235*.\n",
        "\n",
        "#### <font color='red'>**TRY IT**</font> &#x1f9e0;: Let's push our Python skills a little. See you if you can create a function that will help you perform Backward Selection.\n",
        "\n",
        "***Hint***: Try the following process:\n",
        "1. First, set up the base of function (i.e., what goes in and what is returned).\n",
        "2. Next, add some approximate steps in comments to outline how your function will look.\n",
        "3. Finally, fill in each step!"
      ],
      "metadata": {
        "id": "3pxewaGkxf8t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 3. Regularization Methods for Linear Regression\n",
        "\n",
        "### Lasso Regression\n",
        "\n",
        "Let's try out some regularization methods. First we will start with Lasso. The code is very simple. You just have to select a value for\n",
        "α (alpha).\n",
        "\n",
        "- ***High Alpha***: More regularization, simpler model, potentially better generalization, but may underfit.\n",
        "- ***Low Alpha***: Less regularization, more complex model, better fit to training data, but may overfit.\n",
        "\n",
        "Formal ways for selecting a proper alpha include ***Cross-Validation*** and ***Grid Search***. However, let's just practice some manual entries for now so we can understand how it impacts our model.\n",
        "\n",
        "```python\n",
        "# Create and fit the Lasso regression model\n",
        "lasso = Lasso(alpha=0.1)  # Adjust alpha as needed\n",
        "lasso.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the train set to use for eval metrics\n",
        "y_train_pred = lasso.predict(X_train)\n",
        "```\n",
        "#### <font color='red'>**TRY IT**</font> &#x1f9e0;: Start from scratch and incorporate the small code changes above. Select your data (X and y), split the data, fit the model, and evaluate it!"
      ],
      "metadata": {
        "id": "m62Lu4_ZGT9z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ridge Regression\n",
        "\n",
        "Ridge similarly easy to implement with our existing code:\n",
        "\n",
        "```python\n",
        "# Create and fit the Ridge regression model\n",
        "ridge = Ridge(alpha=0.1)  # Adjust alpha as needed\n",
        "ridge.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the training set to use for evaluation metrics\n",
        "y_train_pred = ridge.predict(X_train)\n",
        "```\n",
        "\n",
        "#### <font color='red'>**TRY IT**</font> &#x1f9e0;: Start from scratch and incorporate the small code changes above. Select your data (X and y), split the data, fit the model, and evaluate it!"
      ],
      "metadata": {
        "id": "JVMT3tv1J35X"
      }
    }
  ]
}
