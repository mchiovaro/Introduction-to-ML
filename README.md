# Introduction-to-ML

_An Introductory Course on Machine Learning, Tailored Toward Engineers_

**Welcome!** This course provides and introduction to Machine Learning and it's use across various engineering domains. Download the notebooks, open them in Google Colab, and code along as we cover topics ranging from data preparation and feature engineering; to supervised, unsupervised, and deep learning; to advanced topics and model deployment!

## Outline
Here is a quick description of what each notebook covers:
- `01_Introduction.ipynb`: An overview of how to use Google Colab and a refresher on Python basics.
- `02_Data_Preparation.ipynb`: A walkthrough of popular Data Cleaning and Feature Engineering steps.
- `03_Linear_Regression.ipynb`: A tutorial on Regression Methods: Simple Linear, Multivariate Linear, Lasso, and Ridge Regression. 
- `04_Classifiers_Part_01.ipynb`: Implementing k-Nearest Neighbors and Logistic Regression.
- `05_Classifiers_Part_02_outlined.ipynb`: Building a Decision Tree Classifier from an outline.
- `05_Classifiers_Part_02_scratch.ipynb`: Building a Decision Tree Classifier from scratch.
- `05_Classifiers_Part_02_answer_key.ipynb`: Solution notebook to Decision Tree Classifier lab.
- `06_Classifiers_Part_03.ipynb`: Conducting binary and multi-class classification using Support Vector Machines.
- `07_Random_Forests.ipynb`: Training a popular ensemble model, a Random Forest.
- `08_Clustering.ipynb`: Practicing k-Means and Hierarchical Clustering.
- `09_Neural_Networks.ipynb`: Build a simple 1-layer neural network from scratch, implementing feedforward processes and backpropagation.
- `10_Neural_Networks_Gradient_Descent.ipynb`: Expand upon the code from `09_Neural_Networks.ipynb` to implement variations of gradient descent (stochastic, batch, and mini-batch).

## Contributions
Feel free to submit a pull request for any issues or improvements! \
Author: Megan Chiovaro, PhD (@mchiovaro)
